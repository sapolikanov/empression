{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6880728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3110a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DEPRIVATION\n",
    "########### CREATE DEPRIVATION DATASET\n",
    "# Read the data on deprivation for different years\n",
    "df_deprivation = pd.DataFrame()\n",
    "for year in range(1895, 1904):\n",
    "    append_deprivation = pd.read_excel(\"Data_raw/Deprivation_Rights_MinJust_1894-1903.xlsx\", \n",
    "                                           sheet_name=str(year)).assign(year_deprivation=str(year))\n",
    "    df_deprivation = pd.concat([df_deprivation, append_deprivation], \n",
    "                       ignore_index=True)\n",
    "for year in set(range(1904, 1913)).difference(set(range(1910, 1912))):\n",
    "    append_deprivation = pd.read_excel(\"Data_raw/Deprivation_Rights_MinJust_1904-1914.xlsx\", \n",
    "                                       sheet_name=str(year)).assign(year_deprivation=str(year))\n",
    "    df_deprivation = pd.concat([df_deprivation, append_deprivation], \n",
    "                       ignore_index=True)\n",
    "    \n",
    "# Fix some typos in the courtnames and add cities\n",
    "deprivation_fix_courtnames = pd.read_excel(\"auxiliary data/deprivation_fix_courtnames.xlsx\")\n",
    "df_deprivation = df_deprivation.merge(deprivation_fix_courtnames, left_on='Каким судебным учреждением', \n",
    "                                      right_on='court_old', how='left').drop(columns='court_old')\n",
    "df_deprivation = df_deprivation.drop(columns='Каким судебным учреждением')\n",
    "\n",
    "# Drop duplicates\n",
    "df_deprivation = df_deprivation.drop_duplicates()\n",
    "\n",
    "# Export data\n",
    "df_deprivation.to_excel(\"cleaned_data/deprivation_raw.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee13f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "########### DEPRIVATION\n",
    "########### GEOLOCATE\n",
    "# Done after manual check for duplicates\n",
    "# Read the data\n",
    "df_location = pd.read_stata(\"auxiliary data/Administrative Structure and Coordinates_3.dta\")\n",
    "# Change city names to improve the geolocation\n",
    "df_deprivation['city'].replace({'Елисаветполь' : 'Елизаветполь', 'Кутаиси' : 'Кутаис', 'Ташкент' : 'Ташкентское',\n",
    "                               'Самарканд' : 'Самаркандское', 'Могилёв' : 'Могилев', 'Кишинёв' : 'Кишинев',\n",
    "                               'Орёл' : 'Орел', 'Уральск' : 'Уральское', 'Семипалатинск' : 'Семипалатинское',\n",
    "                               'Новый Маргелан' : 'Маргеланское'}, inplace = True)\n",
    "# Merge the deprivation data with locations\n",
    "df_deprivation_geolocated = pd.merge(df_deprivation, df_location, left_on='city', right_on='volost_new', how='left')\n",
    "# Fix geolocation errors\n",
    "df_deprivation_geolocated = df_deprivation_geolocated[~df_deprivation_geolocated['vnr'].isin([8310, 15319, 12663, 16125, 17325])]\n",
    "df_deprivation_geolocated = df_deprivation_geolocated[df_deprivation_geolocated['villagename'] != \"ст. Усть-Медведицкая\"]\n",
    "\n",
    "# Count the number of unsuccessful matches\n",
    "print(len(df_deprivation_geolocated[df_deprivation_geolocated['gnr'].isna()]))\n",
    "# Export the data\n",
    "df_deprivation_geolocated.to_excel(\"cleaned_data/deprivation_geolocated.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638c74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DEPRIVATION\n",
    "########### COLLAPSE BY PROVINCE-YEAR\n",
    "collapsed_deprivation = df_deprivation_geolocated[['Фамилия','gnr', \n",
    "                           'gub_new', 'year_deprivation']].groupby(['gnr', 'gub_new', 'year_deprivation']).count().unstack(fill_value=0).stack()\n",
    "# Fix index and column names\n",
    "collapsed_deprivation = collapsed_deprivation.reset_index()\n",
    "collapsed_deprivation = collapsed_deprivation.rename(columns={'Фамилия': 'count_deprivation'})\n",
    "# Export the data\n",
    "collapsed_deprivation.to_excel(\"cleaned_data/deprivation_collapsed.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d20fa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352\n",
      "7344\n",
      "7275\n"
     ]
    }
   ],
   "source": [
    "########### OKHRANA\n",
    "########### CREATE OKHRANA DATASET\n",
    "# (1) Read the data on accused from Obzor/Vedomosti for different years \n",
    "df_accused_part1 = pd.read_excel(\"Data_raw/3) list of the accused.xlsx\", \n",
    "                                 sheet_name='1895').drop(columns='№').assign(data_source='accused', years='1895')\n",
    "df_accused_part2 = pd.read_excel(\"Data_raw/3) list of the accused.xlsx\", \n",
    "                                 sheet_name='1895-1896').drop(columns='№').assign(data_source='accused', years='1895-1896')\n",
    "df_accused_part3 = pd.read_excel(\"Data_raw/3) list of the accused.xlsx\", \n",
    "                                 sheet_name='1898-1899').assign(data_source='accused', years='1898-1899')\n",
    "# Fix NA values\n",
    "df_accused_part3['Gendarme custody'] = 'С.-Петербургское'\n",
    "df_accused_part4 = pd.read_excel(\"Data_raw/list of the accused 1900-1901.xlsx\", \n",
    "                                 sheet_name='1900', names=['Gendarme custody', \n",
    "        'Surname', 'Name', 'Patronymic', 'Age', 'Religion', 'Ethnic group', 'title/rank', 'occupation', \n",
    "        'education', 'details', 'crime commited']).assign(data_source='accused', years='1900')\n",
    "# Fix NA values\n",
    "df_accused_part4['Gendarme custody'].fillna('Варшавское', inplace=True)\n",
    "df_accused_part5 = pd.read_excel(\"Data_raw/list of the accused 1900-1901.xlsx\", \n",
    "                                 sheet_name='1901', names=['Gendarme custody', \n",
    "        'Surname', 'Name', 'Patronymic', 'Age', 'Religion', 'Ethnic group', 'title/rank', 'occupation', \n",
    "        'education', 'details', 'crime commited']).assign(data_source='accused', years='1901')\n",
    "# Append the data\n",
    "df_accused = pd.concat([df_accused_part1, df_accused_part2, df_accused_part3, df_accused_part4, df_accused_part5], \n",
    "                       ignore_index=True)\n",
    "# Keep only when name is available\n",
    "df_accused = df_accused[df_accused['Name'].notna()]\n",
    "# Drop empty column\n",
    "df_accused.drop(['Unnamed: 13'], axis=1, inplace=True)\n",
    "\n",
    "# (2) Read the data on lists revolutionaries accused of crimes against the state from Obzor/Vedomosti \n",
    "df_revolutionaries = pd.DataFrame()\n",
    "for year in range(1887, 1898):\n",
    "    append_revolutionaries = pd.read_excel(\"Data_raw/4) Okhrana_Social Conflict_Revolutionaries_Vedomost done.xlsx\", \n",
    "                                           sheet_name=str(year)).assign(data_source='revolutionaries', years=str(year))\n",
    "    df_revolutionaries = pd.concat([df_revolutionaries, append_revolutionaries], \n",
    "                       ignore_index=True)\n",
    "# Fix column names\n",
    "df_revolutionaries.rename({'Patronymic ' : 'Patronymic', 'Details' : 'details'}, inplace=True, axis=1)\n",
    "# Clean the data\n",
    "df_revolutionaries = df_revolutionaries[df_revolutionaries['Gendarme custody']!='В Оловецком и Омском Жандармском Управлениях дознаний произведено не было']\n",
    "# Append to the Okhrana data set\n",
    "df_okhrana = pd.concat([df_accused, df_revolutionaries], join='outer', ignore_index=True)\n",
    "\n",
    "# COMMENTED PART. NOT USED\n",
    "'''\n",
    "# (2B) Append / merge names mentioned in Obzor\n",
    "obzor_names = pd.read_excel(\"Data_raw/names mentioned in Obzor 1900-1901.xlsx\", skiprows=[0])\n",
    "obzor_names.columns = ['Surname', 'Name'] \n",
    "# Create a dummy indicator for names mentioned in Obzor\n",
    "df_okhrana = pd.merge(df_okhrana, obzor_names, on=['Surname', 'Name'], how='outer', indicator=True)\n",
    "# Create 'is_mentioned_obzor' column\n",
    "df_okhrana['is_mentioned_obzor'] = (df_okhrana['_merge'] == 'both').astype(int)\n",
    "# Fill years and data source\n",
    "df_okhrana['years'].fillna('1900-1901', inplace=True)\n",
    "df_okhrana['data_source'].fillna('mentioned_names', inplace=True)\n",
    "# Drop the indicator column\n",
    "df_okhrana = df_okhrana.drop('_merge', axis=1)\n",
    "'''\n",
    "\n",
    "# (3.1) Unify the names of the Gendarme custody\n",
    "# Fix some typos in the courtnames and add cities\n",
    "okhrana_fix_gendarme = pd.read_excel(\"auxiliary data/okhrana_fix_gendarme.xlsx\")\n",
    "df_okhrana = df_okhrana.merge(okhrana_fix_gendarme, left_on='Gendarme custody', \n",
    "                              right_on='gendarme_old', how='left').drop(columns='gendarme_old')\n",
    "\n",
    "# (3.2) Preliminary drop dublicates using all the data from steps (1)-(2)\n",
    "# Print number of observations\n",
    "print(len(df_okhrana))\n",
    "# Drop duplicates inside each of each data_source\n",
    "df_okhrana = df_okhrana.drop_duplicates()\n",
    "print(len(df_okhrana))\n",
    "# More conservative definition of a duplicate (only for observations with surname)\n",
    "df_okhrana_with_surname = df_okhrana[~df_okhrana['Surname'].isna()]\n",
    "df_okhrana_with_surname = df_okhrana_with_surname.drop_duplicates(['Surname', 'Name', 'Patronymic', 'gendarme_new', 'years'])\n",
    "df_okhrana_without_surname = df_okhrana[df_okhrana['Surname'].isna()]\n",
    "df_okhrana = pd.concat([df_okhrana_with_surname, df_okhrana_without_surname], ignore_index=True)\n",
    "print(len(df_okhrana))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e463338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7529\n",
      "7524\n",
      "6754\n"
     ]
    }
   ],
   "source": [
    "# (4) Append / merge People under investigation (4 files with names starting from Alphabet_People)\n",
    "df_investigation_part1_1 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1886.xlsx\", skiprows=[0], \n",
    "                        sheet_name='-178', names=[\"№\", 'Surname', 'Name', 'Patronymic', 'title/rank', 'crime commited',\n",
    "                                                  'Birthplace', 'Date of arrest or sentence', 'Age', \n",
    "                                                  'Distinguishing features', 'details', \n",
    "                                                  'Gendarme custody', 'Responsible official', \n",
    "                                                  'Comments']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1886', investigation_type='politically unreliable')\n",
    "df_investigation_part1_2 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1886.xlsx\", skiprows=[0], \n",
    "                        sheet_name='21-29', names=[\"№\", 'Surname', 'Name', 'Patronymic', 'document', \n",
    "                                                   'Gendarme custody', 'Age', 'Birthplace', \n",
    "                                                   'title/rank']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1886', investigation_type='fled')\n",
    "df_investigation_part1_3 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1886.xlsx\", skiprows=[0], \n",
    "                        sheet_name='30', names=[\"№\", 'Surname', 'Name', 'Patronymic', 'document', \n",
    "                                                   'Gendarme custody', 'Age', 'Birthplace', \n",
    "                                                   'title/rank']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1886', investigation_type='article 246')\n",
    "df_investigation_part1_4 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1886.xlsx\", skiprows=[0], \n",
    "                        sheet_name='31-33', names=[\"№\", 'Surname', 'Name', 'Patronymic', 'title/rank',\n",
    "                                                   'Age', 'crime commited', 'crime date', \n",
    "                                                   'instructions']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1886', investigation_type='non political')\n",
    "\n",
    "df_investigation_part2_1 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1889+1893.xlsx\", skiprows = [0],\n",
    "                            sheet_name='1-338', names=[\"№\", 'Surname', 'Name', 'Patronymic', 'title/rank', 'crime commited',\n",
    "                                                  'Birthdate', 'Date of arrest or sentence', 'Age', \n",
    "                                                  'Gendarme custody', 'Responsible official', \n",
    "                                                  'Comments']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1889', investigation_type='police department')\n",
    "df_investigation_part2_2 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1889+1893.xlsx\", skiprows = [0],\n",
    "                            sheet_name='341-342', names=[\"№\", 'Surname', 'Name', \n",
    "                                                         'Patronymic', 'title/rank', \n",
    "                            'Gendarme custody', \n",
    "                            'Responsible official']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1889', investigation_type='article 246')\n",
    "df_investigation_part2_3 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1889+1893.xlsx\", skiprows = [0],\n",
    "                            sheet_name='343-347', names=[\"№\", 'Surname', 'Name', 'Patronymic', 'title/rank',\n",
    "                            'crime commited',\n",
    "                            'instructions']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1889', investigation_type='non political')\n",
    "df_investigation_part2_4 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1889+1893.xlsx\", skiprows = [0],\n",
    "                        sheet_name='1-198', names=[\"№\", 'Surname', 'Name', 'Patronymic','title/rank', 'crime commited',\n",
    "                        'Birthplace', 'Date of arrest or sentence', 'Age', \n",
    "                        'Gendarme custody', 'Responsible official', \n",
    "                                                   'Comments']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1889', investigation_type='politically unreliable')\n",
    "df_investigation_part2_5 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1889+1893.xlsx\", skiprows = [0],\n",
    "                        sheet_name='1-445', names=[\"№\", 'Surname', 'Name', 'Patronymic',\n",
    "                        'Birthdate', 'Birthplace', 'title/rank', 'crime commited',\n",
    "                        'Date of arrest or sentence', 'Gendarme custody', \n",
    "                        'Responsible official', 'Comments']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1893', investigation_type='police department')\n",
    "df_investigation_part2_6 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1889+1893.xlsx\", skiprows = [0],\n",
    "                        sheet_name='449-490', names=[\"№\", 'Surname', 'Name', 'Patronymic',\n",
    "                        'Birthdate', 'Birthplace', 'title/rank', 'crime commited',\n",
    "                        'Date of arrest or sentence', 'Comments']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1893', investigation_type='measures 1889')\n",
    "df_investigation_part2_7 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1889+1893.xlsx\", skiprows = [0],\n",
    "                        sheet_name='491-525', names=[\"№\", 'Surname', 'Name', 'Patronymic',\n",
    "                        'Birthdate', 'Birthplace', 'title/rank', 'crime commited',\n",
    "                        'Date of arrest or sentence','Gendarme custody', \n",
    "                        'Responsible official', 'Comments']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1893', investigation_type='non political')\n",
    "df_investigation_part3_1 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1899.xlsx\", sheet_name='1', \n",
    "                                         skiprows=[0],\n",
    "             names=[\"№\", 'page', 'Surname', 'Name', 'Patronymic', 'title/rank',\n",
    "                    'Date of arrest', 'details']).drop(columns=['№', 'page']).assign(data_source='investigation', \n",
    "                                                   years='1899', investigation_type='arrest')\n",
    "df_investigation_part3_2 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1899.xlsx\", sheet_name='1-820', \n",
    "                                         skiprows=[0],\n",
    "             names=[\"№\", 'Surname', 'Name', 'Patronymic', 'Birthdate', 'Birthplace', 'title/rank', 'crime commited',\n",
    "                    'Date of arrest or sentence', 'Gendarme custody', 'Responsible official', \n",
    "                    'Comments']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1899', investigation_type='police department')\n",
    "df_investigation_part3_3 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1899.xlsx\", sheet_name='1-820', \n",
    "                                         skiprows=[0],\n",
    "             names=[\"№\", 'Surname', 'Name', 'Patronymic', 'Birthdate', 'Birthplace', 'title/rank', \n",
    "                    'crime commited', 'Date of arrest or sentence', 'Gendarme custody', 'Responsible official', \n",
    "                    'Comments']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1899', investigation_type='measures 1889')\n",
    "df_investigation_part3_4 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1899.xlsx\", skiprows=[0], \n",
    "                        sheet_name='851-905', names=[\"№\", 'Surname', 'Name', 'Patronymic', 'Birthdate', 'title/rank',\n",
    "                        'crime commited', 'ruling date', 'instructions',\n",
    "                        'instructions_2', 'Gendarme custody']).drop(columns='№').assign(data_source='investigation', \n",
    "                                                   years='1899', investigation_type='non political')\n",
    "\n",
    "df_investigation_part4 = pd.read_excel(\"Data_raw/Alphabet_People Under Investigation_1900.xlsx\", skiprows=[0], \n",
    "                        names=['Surname', 'Name', 'Patronymic', 'title/rank', \n",
    "                               'document', 'Birthyear', 'instructions', 'instructions_2',\n",
    "                              'instructions_3']).assign(data_source='investigation', \n",
    "                                                   years='1900', investigation_type='all')\n",
    "\n",
    "df_investigation = pd.concat([df_investigation_part1_1, df_investigation_part1_2, df_investigation_part1_3, \n",
    "                        df_investigation_part1_4, df_investigation_part2_1, df_investigation_part2_2,\n",
    "                        df_investigation_part2_3, df_investigation_part2_4,\n",
    "                        df_investigation_part2_5, df_investigation_part2_6, df_investigation_part2_7,\n",
    "                        df_investigation_part3_1, df_investigation_part3_2,\n",
    "                       df_investigation_part3_3, df_investigation_part3_4, df_investigation_part4], \n",
    "                       ignore_index=True)\n",
    "\n",
    "# (5.1) Unify the names of the Gendarme custody\n",
    "# Fix some typos in the courtnames and add cities\n",
    "investigation_fix_gendarme = pd.read_excel(\"auxiliary data/fix_gendarme_custody_investigation.xlsx\")\n",
    "df_investigation = df_investigation.merge(investigation_fix_gendarme, left_on='Gendarme custody', \n",
    "                              right_on='gendarme_old', how='left').drop(columns='gendarme_old')\n",
    "# (5.2) Drop duplicates from the investigation part\n",
    "# Print number of observations\n",
    "print(len(df_investigation))\n",
    "# Drop full duplicates\n",
    "df_investigation = df_investigation.drop_duplicates()\n",
    "print(len(df_investigation))\n",
    "# More conservative definition of a duplicate (only for observations with surname)\n",
    "df_investigation_with_surname = df_investigation[~df_investigation['Surname'].isna()]\n",
    "df_investigation_with_surname = df_investigation_with_surname.drop_duplicates(['Surname', \n",
    "                                            'Name', 'Patronymic', 'gendarme_new', 'years'])\n",
    "df_investigation_without_surname = df_investigation[df_investigation['Surname'].isna()]\n",
    "df_investigation = pd.concat([df_investigation_with_surname, df_investigation_without_surname], ignore_index=True)\n",
    "print(len(df_investigation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dccaf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14029\n",
      "14000\n",
      "13956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aalip\\AppData\\Local\\Temp\\ipykernel_37208\\4146798880.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_okhrana_large_with_surname['surname'] = df_okhrana_large_with_surname['Surname'].apply(lambda x: str(x).lower())\n",
      "C:\\Users\\aalip\\AppData\\Local\\Temp\\ipykernel_37208\\4146798880.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_okhrana_large_with_surname['name'] = df_okhrana_large_with_surname['Name'].apply(lambda x: str(x).lower())\n",
      "C:\\Users\\aalip\\AppData\\Local\\Temp\\ipykernel_37208\\4146798880.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_okhrana_large_with_surname['patronymic'] = df_okhrana_large_with_surname['Patronymic'].apply(lambda x: str(x).lower())\n"
     ]
    }
   ],
   "source": [
    "# (6) Merge two parts of the Okhrana data\n",
    "df_okhrana_large = pd.concat([df_okhrana, df_investigation], join='outer', ignore_index=True)\n",
    "# Print number of observations\n",
    "print(len(df_okhrana_large))\n",
    "\n",
    "# (7.1) Fix years\n",
    "df_okhrana_large['years'].replace({'1895-1896' : '1896',\n",
    "                               '1898-1899' : '1899'}, inplace = True)\n",
    "df_okhrana_large.rename(columns={\"years\": \"year_okhrana\"}, inplace=True)\n",
    "\n",
    "# (7.2) Additional search for duplicates\n",
    "# account for capital VS lowercase letters\n",
    "df_okhrana_large_without_surname = df_okhrana_large[df_okhrana_large['Surname'].isna()]\n",
    "df_okhrana_large_with_surname = df_okhrana_large[~df_okhrana_large['Surname'].isna()]\n",
    "df_okhrana_large_with_surname['surname'] = df_okhrana_large_with_surname['Surname'].apply(lambda x: str(x).lower())\n",
    "df_okhrana_large_with_surname['name'] = df_okhrana_large_with_surname['Name'].apply(lambda x: str(x).lower())\n",
    "df_okhrana_large_with_surname['patronymic'] = df_okhrana_large_with_surname['Patronymic'].apply(lambda x: str(x).lower())\n",
    "df_okhrana_large_with_surname = df_okhrana_large_with_surname.drop_duplicates(subset=['surname', \n",
    "                                                    'name', 'patronymic', 'gendarme_new', 'year_okhrana'])\n",
    "# Print number of observations\n",
    "df_okhrana_large = pd.concat([df_okhrana_large_without_surname, df_okhrana_large_with_surname], join='outer', ignore_index=True)\n",
    "print(len(df_okhrana_large))\n",
    "# account for missing patronymic case\n",
    "df_okhrana_large_without_patr = df_okhrana_large_with_surname[df_okhrana_large_with_surname['Patronymic'].isna()]\n",
    "df_okhrana_large_with_patr = df_okhrana_large_with_surname[~df_okhrana_large_with_surname['Patronymic'].isna()]\n",
    "# Create a dummy indicator for names existing also with patronymic\n",
    "df_okhrana_large_without_patr = pd.merge(df_okhrana_large_without_patr, \n",
    "                                df_okhrana_large_with_patr, on=['surname', 'name',\n",
    "                                                               'gendarme_new', 'year_okhrana'], how='left', \n",
    "                                         suffixes = ['', '_drop'], indicator=True)\n",
    "# Drop unnecessary columns\n",
    "df_okhrana_large_without_patr = df_okhrana_large_without_patr[df_okhrana_large_without_patr['_merge']=='left_only']\n",
    "df_okhrana_large_without_patr = df_okhrana_large_without_patr[df_okhrana_large_without_patr.columns.drop(list(df_okhrana_large_without_patr.filter(regex='_drop')))]\n",
    "# Print number of observations\n",
    "df_okhrana_large = pd.concat([df_okhrana_large_without_surname, df_okhrana_large_without_patr,\n",
    "                             df_okhrana_large_with_patr], join='outer', ignore_index=True)\n",
    "df_okhrana_large.drop(columns=['surname', 'name', 'patronymic', '_merge'], inplace=True)\n",
    "print(len(df_okhrana_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb7540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5219\n"
     ]
    }
   ],
   "source": [
    "# (8) Geolocate Okhrana data\n",
    "# Read the data\n",
    "df_location = pd.read_stata(\"auxiliary data/Administrative Structure and Coordinates_3.dta\")\n",
    "# Change city names to improve the geolocation\n",
    "df_okhrana_large['city'].replace({'Елисаветполь' : 'Елизаветполь', 'Кутаиси' : 'Кутаис', 'Ташкент' : 'Ташкентское',\n",
    "                               'Самарканд' : 'Самаркандское', 'Могилёв' : 'Могилев', 'Кишинёв' : 'Кишинев',\n",
    "                               'Орёл' : 'Орел', 'Уральск' : 'Уральское', 'Семипалатинск' : 'Семипалатинское',\n",
    "                               'Новый Маргелан' : 'Маргеланское'}, inplace = True)\n",
    "# Merge the deprivation data with locations\n",
    "df_okhrana_geolocated = pd.merge(df_okhrana_large, df_location, left_on='city', right_on='volost_new', how='left')\n",
    "# Fix geolocation errors\n",
    "df_okhrana_geolocated = df_okhrana_geolocated[~df_okhrana_geolocated['vnr'].isin([15319, 12663, 16125, 16918, \n",
    "                                                                                                17325])]\n",
    "df_okhrana_geolocated = df_okhrana_geolocated[df_okhrana_geolocated['villagename'] != \"ст. Усть-Медведицкая\"]\n",
    "\n",
    "# Count the number of unsuccessful matches\n",
    "print(len(df_okhrana_geolocated[df_okhrana_geolocated['gnr'].isna()]))\n",
    "# Export the data\n",
    "df_okhrana_geolocated.to_excel(\"cleaned_data/okhrana_geolocated.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7706e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### OKHRANA\n",
    "########### COLLAPSE BY PROVINCE-YEAR\n",
    "df_okhr_for_collapse = df_okhrana_geolocated[~df_okhrana_geolocated['gnr'].isna()]\n",
    "df_okhr_for_collapse = df_okhr_for_collapse.assign(count_okhrana=1)\n",
    "collapsed_okhrana = df_okhr_for_collapse[['count_okhrana','gnr', \n",
    "                           'gub_new', 'year_okhrana']].groupby(['gnr', 'gub_new', 'year_okhrana']).count().unstack(fill_value=0).stack()\n",
    "# Fix index \n",
    "collapsed_okhrana = collapsed_okhrana.reset_index()\n",
    "# Export the data\n",
    "collapsed_okhrana.to_excel(\"cleaned_data/okhrana_collapsed.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
